\section{Conclusion}
On remarque certaines limites à notre mécanisme d'apprentissage. En effet,
l'apprentissage peut mener à des configurations non réversibles. Le fait de
trop stimuler une entrée peut amener des poids à devenir négligeables et ainsi
il devient alors impossible pour ces poids d'augmenter par la suite car ils
ne suffisent plus à activer le neurone. Les réseaux ont donc tendance à converger
vers une certaine configuration extrême : certains poids à 0 et d'autres 1. Il
aurait été intéressant de raffiner cette méthode d'apprentissage afin qu'un 
poids négligeable puisse quand même croître à nouveau. Ainsi il aurait
été possible d'éviter que le réseau converge forcement vers un cas extrême.
